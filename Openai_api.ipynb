{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "157449b4-beae-4594-b4ac-5c4ca4073eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from dhlab.nbtokenizer import tokenize\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97bcfc9a-8d6e-4f64-955d-01077ec1ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba44231-36fc-460f-abea-8fb3f82e8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the character list with indices\n",
    "characters = [\n",
    "    'JOHANNES ROSMER',\n",
    "    'REBEKKA WEST',\n",
    "    'REKTOR KROLL',\n",
    "    'ULRIK BRENDEL',\n",
    "    'PEDER MORTENSGÅRD',\n",
    "    'MADAM HELSETH'\n",
    "]\n",
    "\n",
    "# Create a prefixed character list with indices\n",
    "character_index = \"\\n\".join([f\"{i+1}: {name}\" for i, name in enumerate(characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3dad7f33-57cf-446b-87d8-54adccafa0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: JOHANNES ROSMER\n",
      "2: REBEKKA WEST\n",
      "3: REKTOR KROLL\n",
      "4: ULRIK BRENDEL\n",
      "5: PEDER MORTENSGÅRD\n",
      "6: MADAM HELSETH\n"
     ]
    }
   ],
   "source": [
    "print(character_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ed20816-6cf5-44e7-b92f-7a472802a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(character_index, act_name, act_text):\n",
    "    prompt = f\"\"\"Characters in {act_name}:\n",
    "{character_index}\n",
    "\n",
    "Structure:\n",
    "- Each line of dialogue begins with an uppercase character name, followed by their statement.\n",
    "- Character names always appear in uppercase to distinguish them from regular text.\n",
    "- Pronouns should refer to the speaker or other characters listed above based on context.\n",
    "\n",
    "Instructions:\n",
    "- With each pronoun resolve it and add the character ID(s) behind it, formatted in square brackets (e.g., [1]).\n",
    "- For collective pronouns like \"vi\" (we), use a list of character IDs in brackets, e.g., [1, 2].\n",
    "- Do not add any additional commentary; provide only the modified text with pronouns replaced.\n",
    "- Return the output as a JSON list of objects, where each object is a tuple like this\n",
    "(the name of the character speaking, the dialogue text with pronouns replaced by IDs)\n",
    "\n",
    "Example Output:\n",
    "\n",
    "[\n",
    "(\"MADAM HELSETH\", \"Å, det er ikke værdt at snakke om det. Sligt noget tror nu ikke De [2] på heller.\"),\n",
    "(\"REBEKKA\", \"Tror da De [6] på det?\"),\n",
    "  ...\n",
    "]\n",
    "\n",
    "- Provide only the JSON output with no labels, explanations, or additional text. Do not prefix the JSON with \"json\" or any other text.\n",
    "\n",
    "Text:\n",
    "{act_text}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7739d8f-528b-442e-bf18-e13093ed21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7223dabb-114c-435b-a6d6-8d098eebbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Rosmersholm.json\") as fp:\n",
    "    acts = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54f58ac8-347c-4979-87eb-41c69bcba52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, split_by_lines=150):\n",
    "    lines = text.splitlines()\n",
    "    midpoint = len(lines) // 2\n",
    "    part1 = \"\\n\".join(lines[:midpoint])\n",
    "    part2 = \"\\n\".join(lines[midpoint:])\n",
    "    return part1, part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9ab7345-d746-436a-8f7e-53876096e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 token count: 6574\n",
      "Part 2 token count: 5608\n"
     ]
    }
   ],
   "source": [
    "# Use the split function on each act\n",
    "part1, part2 = split_text(acts[0]['text'])\n",
    "\n",
    "# Verify token counts for each part\n",
    "print(\"Part 1 token count:\", count_tokens(part1))\n",
    "print(\"Part 2 token count:\", count_tokens(part2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899049be-2aee-4a1b-97ba-0263d17ecb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65de6b5-4ba7-45c2-b6ca-e129718a5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function for analyzing text\n",
    "def analyze_chunk(input_prompt):\n",
    "    # Request the model for the completion\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",  \n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Return the response content (the analyzed XML)\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15a6d230-8634-40e5-8a76-6bd35046876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "act:   0%|                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "line_part:   0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "line_part:  50%|████████████████████████████████████▌                                    | 1/2 [01:48<01:48, 108.21s/it]\u001b[A\n",
      "line_part: 100%|█████████████████████████████████████████████████████████████████████████| 2/2 [03:31<00:00, 105.75s/it]\u001b[A\n",
      "act:  33%|██████████████████████████▎                                                    | 1/3 [03:31<07:03, 211.51s/it]\n",
      "line_part:   0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "line_part:  50%|█████████████████████████████████████                                     | 1/2 [01:27<01:27, 87.63s/it]\u001b[A\n",
      "line_part: 100%|██████████████████████████████████████████████████████████████████████████| 2/2 [03:09<00:00, 94.72s/it]\u001b[A\n",
      "act:  67%|████████████████████████████████████████████████████▋                          | 2/3 [06:40<03:18, 198.53s/it]\n",
      "line_part:   0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "line_part:  50%|█████████████████████████████████████                                     | 1/2 [01:07<01:07, 67.00s/it]\u001b[A\n",
      "line_part: 100%|██████████████████████████████████████████████████████████████████████████| 2/2 [02:32<00:00, 76.27s/it]\u001b[A\n",
      "act: 100%|███████████████████████████████████████████████████████████████████████████████| 3/3 [09:13<00:00, 184.50s/it]\n"
     ]
    }
   ],
   "source": [
    "#results = []\n",
    "for act in tqdm(acts[1:], 'act'):\n",
    "    for part in  tqdm(split_text(act['text']), 'line_part'):\n",
    "        results.append(analyze_chunk(create_prompt(character_index, act['act_name'], part)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0261a1b0-1f9e-4980-8c3a-5fc76bed8325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenize(results[0].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3abb2a3-f8d9-4f2e-a4da-912915002e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_result = []\n",
    "for r in results:\n",
    "    end_result.append(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "254d9bd5-3251-4000-9a9c-0c4c6014c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Rosmersholm_analyse_2.json', \"w\") as fp:\n",
    "    json.dump(end_result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "193f9c2f-453c-4d6d-94c3-7ee294d2b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example API response with Markdown formatting\n",
    "response = []\n",
    "for i, res in enumerate(results):\n",
    "    response_text = res.content\n",
    "    # Remove '```json' and '```' if present\n",
    "    if response_text.startswith(\"```json\"):\n",
    "        response_text = response_text.replace(\"```json\",\"\")  # Remove the initial ```json\n",
    "    if response_text.endswith(\"```\"):\n",
    "        response_text = response_text.replace(\"```\",\"\")  # Remove the trailing ```\n",
    "    \n",
    "    #print(response_text)\n",
    "    # Strip any extra whitespace and parse as JSON\n",
    "    parsed_response = ast.literal_eval(response_text.strip())\n",
    "    response.append((\"act\", str(i)))\n",
    "    response +=parsed_response\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1716ca3d-01c1-428e-bfec-7095f6ab613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rosmer = pd.DataFrame(response, columns=[\"Taler\", \"Dialog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "23824f8a-ea4c-440e-bc36-3d2655fcb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rosmer.to_excel(\"Rosmersholm_refs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fe83c7a-c0da-489a-bd6f-2bf614b45491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72464036-c2f6-4b42-96bd-8f11befdf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 8730\n",
      "Token count: 7817\n",
      "Token count: 8500\n",
      "Token count: 8172\n",
      "Token count: 6890\n",
      "Token count: 7048\n",
      "Token count: 5460\n",
      "Token count: 6209\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Use the tokenizer for the specific model you're working with\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")  # or \"gpt-4o\" if you have it\n",
    "\n",
    "# Count tokens in your string\n",
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "for res in results:\n",
    "    text = res.content  # Replace with your actual act text\n",
    "    token_count = count_tokens(text)\n",
    "    print(\"Token count:\", token_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6e4fd5c3-2a2c-4121-96ab-18f68a87232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3975cf34-cec2-4566-929a-fd61c1852e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rosmer['Referanser'] = df_rosmer.Dialog.apply(lambda x: re.findall(r'(\\[.*?\\])', x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2568147a-7b22-4310-9e6c-4bcb876151a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
